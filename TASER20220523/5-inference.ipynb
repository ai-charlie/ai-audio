{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-delta",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import ast\n",
    "import torch\n",
    "from ts.torch_handler.base_handler import BaseHandler\n",
    "import io\n",
    "import torchaudio\n",
    "import torchvision\n",
    "from omegaconf import OmegaConf\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets.vision import VisionDataset\n",
    "from torchvision.io import (\n",
    "    read_video_timestamps,\n",
    "    read_video\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "from mmf.common.sample import Sample, SampleList\n",
    "from mmf.utils.env import set_seed, setup_imports\n",
    "from mmf.utils.logger import setup_logger, setup_very_basic_config\n",
    "from mmf.datasets.base_dataset import BaseDataset\n",
    "from mmf.utils.build import build_encoder, build_model, build_processors\n",
    "from mmf.datasets.mmf_dataset_builder import MMFDatasetBuilder\n",
    "from torch.utils.data import IterableDataset\n",
    "from mmf.utils.configuration import load_yaml\n",
    "from mmf.models.mmf_transformer import MMFTransformer\n",
    "\n",
    "class MMFHandler(BaseHandler):\n",
    "    \"\"\"\n",
    "    Transformers handler class for  MMFTransformerWithVideoAudio model.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(MMFHandler, self).__init__()\n",
    "        self.initialized = False\n",
    "\n",
    "    def initialize(self, ctx):\n",
    "        self.manifest = ctx.manifest\n",
    "        properties = ctx.system_properties\n",
    "        model_dir = properties.get(\"model_dir\")\n",
    "        serialized_file = self.manifest['model']['serializedFile']\n",
    "        model_pt_path = os.path.join(model_dir, serialized_file)\n",
    "        self.map_location = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.device = torch.device(\n",
    "            self.map_location + \":\" + str(properties.get(\"gpu_id\"))\n",
    "            if torch.cuda.is_available()\n",
    "            else self.map_location\n",
    "        )\n",
    "\n",
    "        # reading the csv file which include all the labels in the dataset to make the class/index mapping\n",
    "        # and matching the output of the model with num labels from dataset\n",
    "        df = pd.read_csv('./charades_action_lables.csv')\n",
    "        label_set = set()\n",
    "        df['action_labels'] = df['action_labels'].str.replace('\"','')\n",
    "        labels_initial = df['action_labels'].tolist()\n",
    "        labels = []\n",
    "        for sublist in labels_initial:\n",
    "            new_sublist = ast.literal_eval(sublist)\n",
    "            labels.append(new_sublist)\n",
    "            for item in new_sublist:\n",
    "                label_set.add(item)\n",
    "        classes = sorted(list(label_set))\n",
    "        self.class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
    "        self.classes = classes\n",
    "        self.labels = labels\n",
    "        self.idx_to_class = classes\n",
    "        config = OmegaConf.load('config.yaml')\n",
    "        print(\"*********** config keyssss **********\", config.keys())\n",
    "        setup_very_basic_config()\n",
    "        setup_imports()\n",
    "        self.model = MMFTransformer(config.model_config.mmf_transformer)\n",
    "        self.model.build()\n",
    "        self.model.init_losses()\n",
    "        self.processor = build_processors(\n",
    "            config.dataset_config[\"charades\"].processors\n",
    "        )\n",
    "        state_dict = torch.load(serialized_file, map_location=self.device)\n",
    "        self.model.load_state_dict(state_dict)\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        self.initialized = True\n",
    "        print(\"********* files in temp direcotry that .mar file got extracted *********\", os.listdir(model_dir))\n",
    "\n",
    "    def preprocess(self, requests):\n",
    "        \"\"\" Preprocessing, based on processor defined for MMF model.\n",
    "            \"\"\"\n",
    "\n",
    "        def create_sample(video_transfomred,audio_transfomred,text_tensor, video_label):\n",
    "\n",
    "            label = [self.class_to_idx[l] for l in video_label]\n",
    "\n",
    "            one_hot_label = torch.zeros(len(self.class_to_idx))\n",
    "            one_hot_label[label] = 1\n",
    "\n",
    "            current_sample= Sample()\n",
    "            current_sample.video = video_transfomred\n",
    "            current_sample.audio = audio_transfomred\n",
    "            current_sample.update(text_tensor)\n",
    "            current_sample.targets = one_hot_label\n",
    "            current_sample.dataset_type = 'test'\n",
    "            current_sample.dataset_name = 'charades'\n",
    "            return SampleList([current_sample]).to(self.device)\n",
    "\n",
    "        for idx, data in enumerate(requests):\n",
    "            raw_script = data.get('script')\n",
    "            script = raw_script.decode('utf-8')\n",
    "            raw_label = data.get('labels')\n",
    "            video_label = raw_label.decode('utf-8')\n",
    "            video_label = [video_label]\n",
    "            \n",
    "            video = io.BytesIO(data['data'])\n",
    "            video_tensor, audio_tensor,info = torchvision.io.read_video(video)\n",
    "            text_tensor = self.processor[\"text_processor\"]({\"text\": script})\n",
    "            video_transformed = self.processor[\"video_test_processor\"](video_tensor)\n",
    "            audio_transformed = self.processor[\"audio_processor\"](audio_tensor)\n",
    "            samples = create_sample(video_transformed,audio_transformed,text_tensor,video_label)\n",
    "\n",
    "        return samples\n",
    "\n",
    "    def inference(self, samples):\n",
    "        \"\"\" Predict the class (or classes) of the received text using the serialized transformers checkpoint.\n",
    "        \"\"\"\n",
    "        if torch.cuda.is_available():\n",
    "            with torch.cuda.device(samples.get_device()):\n",
    "                output = self.model(samples)\n",
    "        else:\n",
    "            output = self.model(samples)\n",
    "            \n",
    "        sigmoid_scores = torch.sigmoid(output[\"scores\"])\n",
    "        binary_scores = torch.round(sigmoid_scores)\n",
    "        score = binary_scores[0]\n",
    "        score = score.nonzero()\n",
    "\n",
    "        predictions = []\n",
    "        for item in score:\n",
    "            predictions.append(self.idx_to_class[item.item()])\n",
    "        print(\"************** predictions *********\", predictions)\n",
    "        return predictions\n",
    "\n",
    "    def postprocess(self, inference_output):\n",
    "        # TODO: Add any needed post-processing of the model predictions here\n",
    "        return [inference_output]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch-g]",
   "language": "python",
   "name": "conda-env-pytorch-g-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

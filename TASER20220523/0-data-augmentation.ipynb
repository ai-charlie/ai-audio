{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "substantial-trader",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchaudio.transforms as T\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "\n",
    "import IPython.display as ipd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "quiet-potter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>P</th>\n",
       "      <th>A</th>\n",
       "      <th>speaker</th>\n",
       "      <th>sex</th>\n",
       "      <th>path</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4059</th>\n",
       "      <td>6607</td>\n",
       "      <td>-0.434956</td>\n",
       "      <td>0.939179</td>\n",
       "      <td>SER0030</td>\n",
       "      <td>female</td>\n",
       "      <td>./SER0030/6607.wav</td>\n",
       "      <td>PL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id         P         A  speaker     sex                path emotion\n",
       "4059  6607 -0.434956  0.939179  SER0030  female  ./SER0030/6607.wav      PL"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义自己的数据集\n",
    "# 使用pandas 连接label下的文件\n",
    "talser_path='D:/data/TAL-SER/'\n",
    "label_df = pd.read_csv(talser_path+\"label/label\",sep=\" \")\n",
    "utt2gen_df = pd.read_csv(talser_path+\"label/utt2gen\",sep=\" \",header=None,names=['id','sex'])\n",
    "utt2spk_df = pd.read_csv(talser_path+\"label/utt2spk\",sep=\" \",header=None,names=['id','speaker'])\n",
    "wavscp_df = pd.read_csv(talser_path+\"label/wavscp\",sep=\" \",header=None,names=['id','path'])\n",
    "wavscp_df.sort_values('id', ignore_index=True,inplace =True)\n",
    "data_df = pd.concat([label_df, utt2spk_df['speaker'], utt2gen_df['sex'],wavscp_df['path']], axis=1)\n",
    "# data_df[\"path\"].replace(\".\\/S\", talser_path+\"S\", regex=True,inplace =True)\n",
    "del label_df\n",
    "del utt2gen_df\n",
    "del utt2spk_df\n",
    "del wavscp_df\n",
    "\n",
    "def function(P, A):\n",
    "    if  P>0:\n",
    "        if A>0:\n",
    "            return 'AH'\n",
    "        else:\n",
    "            return 'PH'\n",
    "    else:\n",
    "        if A<0:\n",
    "            return 'AL'\n",
    "        else:\n",
    "            return 'PL'\n",
    "data_df['emotion'] = data_df.apply(lambda x: function(x.P, x.A), axis = 1)\n",
    "\n",
    "data_df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "settled-honduras",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "try:\n",
    "    from torch_audiomentations import Compose, Gain, PolarityInversion\n",
    "except:\n",
    "    !pip install torch-audiomentations\n",
    "\n",
    "\n",
    "# Initialize augmentation callable\n",
    "apply_augmentation = Compose(\n",
    "    transforms=[\n",
    "        Gain(\n",
    "            min_gain_in_db=-15.0,\n",
    "            max_gain_in_db=5.0,\n",
    "            p=0.5,\n",
    "        ),\n",
    "        PolarityInversion(p=0.5)\n",
    "    ]\n",
    ")\n",
    "\n",
    "torch_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Make an example tensor with white noise.\n",
    "# This tensor represents 8 audio snippets with 2 channels (stereo) and 2 s of 16 kHz audio.\n",
    "audio_samples = torch.rand(size=(8, 2, 32000), dtype=torch.float32, device=torch_device) - 0.5\n",
    "\n",
    "# Apply augmentation. This varies the gain and polarity of (some of)\n",
    "# the audio snippets in the batch independently.\n",
    "perturbed_audio_samples = apply_augmentation(audio_samples, sample_rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "built-hardwood",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch-g]",
   "language": "python",
   "name": "conda-env-pytorch-g-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

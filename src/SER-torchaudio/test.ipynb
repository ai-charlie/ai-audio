{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jun  1 00:35:38 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.86       Driver Version: 470.86       CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA TITAN Xp     Off  | 00000000:02:00.0 Off |                  N/A |\n",
      "| 25%   35C    P8    10W / 250W |   2084MiB / 12196MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA TITAN Xp     Off  | 00000000:03:00.0 Off |                  N/A |\n",
      "| 31%   44C    P8    11W / 250W |   1071MiB / 12196MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA TITAN Xp     Off  | 00000000:82:00.0 Off |                  N/A |\n",
      "| 31%   43C    P8    11W / 250W |   1216MiB / 12196MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA TITAN Xp     Off  | 00000000:83:00.0 Off |                  N/A |\n",
      "| 31%   43C    P8    11W / 250W |   1069MiB / 12196MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1499      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    0   N/A  N/A   1383838      C   /opt/anaconda3/bin/python        1473MiB |\n",
      "|    0   N/A  N/A   1383942      C   /opt/anaconda3/bin/python         603MiB |\n",
      "|    1   N/A  N/A      1499      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    1   N/A  N/A   1383838      C   /opt/anaconda3/bin/python        1063MiB |\n",
      "|    2   N/A  N/A      1499      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    2   N/A  N/A   1315644      C   ...ffice/program/soffice.bin      145MiB |\n",
      "|    2   N/A  N/A   1383838      C   /opt/anaconda3/bin/python        1063MiB |\n",
      "|    3   N/A  N/A      1499      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    3   N/A  N/A   1383838      C   /opt/anaconda3/bin/python        1061MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd /mnt/pci-0000:00:1f.2-ata-1-part1/torchaudio\n",
    "!CUDA_VISIBLE_DEVICES=0,1,2,3 python -m torch.distributed.launch --nproc_per_node=4 main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "\n",
      "PackagesNotFoundError: The following packages are not available from current channels:\n",
      "\n",
      "  - wordcloud\n",
      "\n",
      "Current channels:\n",
      "\n",
      "  - https://repo.anaconda.com/pkgs/main/linux-64\n",
      "  - https://repo.anaconda.com/pkgs/main/noarch\n",
      "  - https://repo.anaconda.com/pkgs/r/linux-64\n",
      "  - https://repo.anaconda.com/pkgs/r/noarch\n",
      "\n",
      "To search for alternate channels that may provide the conda package you're\n",
      "looking for, navigate to\n",
      "\n",
      "    https://anaconda.org\n",
      "\n",
      "and use the search bar at the top of the page.\n",
      "\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import ast\n",
    "import torch\n",
    "from ts.torch_handler.base_handler import BaseHandler\n",
    "import io\n",
    "import torchaudio\n",
    "import torchvision\n",
    "from omegaconf import OmegaConf\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets.vision import VisionDataset\n",
    "from torchvision.io import (\n",
    "    read_video_timestamps,\n",
    "    read_video\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "from mmf.common.sample import Sample, SampleList\n",
    "from mmf.utils.env import set_seed, setup_imports\n",
    "from mmf.utils.logger import setup_logger, setup_very_basic_config\n",
    "from mmf.datasets.base_dataset import BaseDataset\n",
    "from mmf.utils.build import build_encoder, build_model, build_processors\n",
    "from mmf.datasets.mmf_dataset_builder import MMFDatasetBuilder\n",
    "from torch.utils.data import IterableDataset\n",
    "from mmf.utils.configuration import load_yaml\n",
    "from mmf.models.mmf_transformer import MMFTransformer\n",
    "\n",
    "class MMFHandler(BaseHandler):\n",
    "    \"\"\"\n",
    "    Transformers handler class for  MMFTransformerWithVideoAudio model.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(MMFHandler, self).__init__()\n",
    "        self.initialized = False\n",
    "\n",
    "    def initialize(self, ctx):\n",
    "        self.manifest = ctx.manifest\n",
    "        properties = ctx.system_properties\n",
    "        model_dir = properties.get(\"model_dir\")\n",
    "        serialized_file = self.manifest['model']['serializedFile']\n",
    "        model_pt_path = os.path.join(model_dir, serialized_file)\n",
    "        self.map_location = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.device = torch.device(\n",
    "            self.map_location + \":\" + str(properties.get(\"gpu_id\"))\n",
    "            if torch.cuda.is_available()\n",
    "            else self.map_location\n",
    "        )\n",
    "\n",
    "        # reading the csv file which include all the labels in the dataset to make the class/index mapping\n",
    "        # and matching the output of the model with num labels from dataset\n",
    "        df = pd.read_csv('./charades_action_lables.csv')\n",
    "        label_set = set()\n",
    "        df['action_labels'] = df['action_labels'].str.replace('\"','')\n",
    "        labels_initial = df['action_labels'].tolist()\n",
    "        labels = []\n",
    "        for sublist in labels_initial:\n",
    "            new_sublist = ast.literal_eval(sublist)\n",
    "            labels.append(new_sublist)\n",
    "            for item in new_sublist:\n",
    "                label_set.add(item)\n",
    "        classes = sorted(list(label_set))\n",
    "        self.class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
    "        self.classes = classes\n",
    "        self.labels = labels\n",
    "        self.idx_to_class = classes\n",
    "        config = OmegaConf.load('config.yaml')\n",
    "        print(\"*********** config keyssss **********\", config.keys())\n",
    "        setup_very_basic_config()\n",
    "        setup_imports()\n",
    "        self.model = MMFTransformer(config.model_config.mmf_transformer)\n",
    "        self.model.build()\n",
    "        self.model.init_losses()\n",
    "        self.processor = build_processors(\n",
    "            config.dataset_config[\"charades\"].processors\n",
    "        )\n",
    "        state_dict = torch.load(serialized_file, map_location=self.device)\n",
    "        self.model.load_state_dict(state_dict)\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        self.initialized = True\n",
    "        print(\"********* files in temp direcotry that .mar file got extracted *********\", os.listdir(model_dir))\n",
    "\n",
    "    def preprocess(self, requests):\n",
    "        \"\"\" Preprocessing, based on processor defined for MMF model.\n",
    "            \"\"\"\n",
    "\n",
    "        def create_sample(video_transfomred,audio_transfomred,text_tensor, video_label):\n",
    "\n",
    "            label = [self.class_to_idx[l] for l in video_label]\n",
    "\n",
    "            one_hot_label = torch.zeros(len(self.class_to_idx))\n",
    "            one_hot_label[label] = 1\n",
    "\n",
    "            current_sample= Sample()\n",
    "            current_sample.video = video_transfomred\n",
    "            current_sample.audio = audio_transfomred\n",
    "            current_sample.update(text_tensor)\n",
    "            current_sample.targets = one_hot_label\n",
    "            current_sample.dataset_type = 'test'\n",
    "            current_sample.dataset_name = 'charades'\n",
    "            return SampleList([current_sample]).to(self.device)\n",
    "\n",
    "        for idx, data in enumerate(requests):\n",
    "            raw_script = data.get('script')\n",
    "            script = raw_script.decode('utf-8')\n",
    "            raw_label = data.get('labels')\n",
    "            video_label = raw_label.decode('utf-8')\n",
    "            video_label = [video_label]\n",
    "            \n",
    "            video = io.BytesIO(data['data'])\n",
    "            video_tensor, audio_tensor,info = torchvision.io.read_video(video)\n",
    "            text_tensor = self.processor[\"text_processor\"]({\"text\": script})\n",
    "            video_transformed = self.processor[\"video_test_processor\"](video_tensor)\n",
    "            audio_transformed = self.processor[\"audio_processor\"](audio_tensor)\n",
    "            samples = create_sample(video_transformed,audio_transformed,text_tensor,video_label)\n",
    "\n",
    "        return samples\n",
    "\n",
    "    def inference(self, samples):\n",
    "        \"\"\" Predict the class (or classes) of the received text using the serialized transformers checkpoint.\n",
    "        \"\"\"\n",
    "        if torch.cuda.is_available():\n",
    "            with torch.cuda.device(samples.get_device()):\n",
    "                output = self.model(samples)\n",
    "        else:\n",
    "            output = self.model(samples)\n",
    "            \n",
    "        sigmoid_scores = torch.sigmoid(output[\"scores\"])\n",
    "        binary_scores = torch.round(sigmoid_scores)\n",
    "        score = binary_scores[0]\n",
    "        score = score.nonzero()\n",
    "\n",
    "        predictions = []\n",
    "        for item in score:\n",
    "            predictions.append(self.idx_to_class[item.item()])\n",
    "        print(\"************** predictions *********\", predictions)\n",
    "        return predictions\n",
    "\n",
    "    def postprocess(self, inference_output):\n",
    "        # TODO: Add any needed post-processing of the model predictions here\n",
    "        return [inference_output]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

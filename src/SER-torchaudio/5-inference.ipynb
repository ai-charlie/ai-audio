{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d016485",
   "metadata": {},
   "source": [
    "# 拆分长音频并进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6b16378",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import librosa\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchaudio.transforms as T\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "\n",
    "import IPython.display as ipd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d3acaa",
   "metadata": {},
   "source": [
    "## 使用sox拆分音频"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84ac60e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sox FAIL formats: can't open output file `/home/tx/AI/output/silence/samplewav_001.wav': No such file or directory\n",
      "sox WARN trim: Last 1 position(s) not reached (audio shorter than expected).\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_WAV_PATH = \"/home/tx/AI/torchaudio/input/2019mchn_001.wav\"\n",
    "!sox ~/AI/torchaudio/input/2019mchn_001.wav ~/AI/output/silence/silence_.wav silence 1 2 0.5% 1 4.0 0.9% : newfile : restart\n",
    "!sox /home/tx/AI/torchaudio/input/2019mchn_001.wav 'output/10s/samplewav_.wav' trim 0 10 : newfile : restart\n",
    "# 比如执行 sox ~/Music/PI_ringtone.mp3  ~/Music/PI_ringtone.mp3 trim 0 15.5 : newfile : restart \n",
    "# 会在 ~/Music/ 目录下生成名称前缀为 PI_ringtone、 格式为 .mp3、时长为 15.5 秒的若干个音频片段 。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6024c6",
   "metadata": {},
   "source": [
    "## 使用pydub拆分音频"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8b258e",
   "metadata": {},
   "outputs": [],
   "source": [
    "myaudio = AudioSegment.from_file(SAMPLE_WAV_PATH , \"wav\")\n",
    "chunk_length_ms = 1000 # 分块的毫秒数\n",
    "chunks = make_chunks(myaudio, chunk_length_ms) #将文件切割成1秒每块\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    try:\n",
    "        wav_info = sox.file_info.info(wav_path)  # TODO\n",
    "    except sox.core.SoxiError as e:\n",
    "        print('Invalid wav file: {}, exception raised ( {} ), maybe because invalid RIFF header'.format(wav_path, e))\n",
    "    # wav_info['silent'] == True 认为该音频silent\n",
    "    if wav_info['silent'] != False:\n",
    "        print('Invalid wav file: {}, silent is {}'.format(wav_path, wav_info['silent']))\n",
    "\n",
    "    waveform, sample_rate = torchaudio.load(filepath)\n",
    "    ipd.Audio(waveform.numpy(), rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc71fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "import os\n",
    "\n",
    "# 初始化\n",
    "audiopath = \"/home/tx/AI/torchaudio/input/2019mchn_001.wav\"\n",
    "audiotype = 'wav' #如果wav、mp4其他格式参看pydub.AudioSegment的API\n",
    "waveform,sample_rate = torchaudio.load(audiopath)\n",
    "\n",
    "\n",
    "metadata = torchaudio.info(audiopath)\n",
    "print(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f662b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample_rate = sample_rate/2\n",
    "\n",
    "# Since Resample applies to a single channel, we resample first channel here\n",
    "channel = 0\n",
    "transformed = torchaudio.transforms.Resample(sample_rate, new_sample_rate)(waveform[channel,:].view(1,-1))\n",
    "\n",
    "print(\"Shape of transformed waveform: {}\".format(transformed.size()))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(transformed[0,:1000].numpy())\n",
    "torchaudio.save(,transformed[0,:1000],new_sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dceda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 读入音频\n",
    "print('读入音频')\n",
    "sound = AudioSegment.from_file(audiopath, format=audiotype)\n",
    "# sound = sound[:3*60*1000] #如果文件较大，先取前3分钟测试，根据测试结果，调整参数\n",
    "# 分割 \n",
    "print('开始分割')\n",
    "chunks = split_on_silence(sound,min_silence_len=300,silence_thresh=-30)#min_silence_len: 拆分语句时，静默满0.3秒则拆分。silence_thresh：小于-70dBFS以下的为静默。\n",
    "# 创建保存目录\n",
    "filepath = os.path.split(audiopath)[0]\n",
    "chunks_path = filepath+'/chunks/'\n",
    "if not os.path.exists(chunks_path):os.mkdir(chunks_path)\n",
    "# 保存所有分段\n",
    "print(f'开始保存{len(chunks)}个文件')\n",
    "for i in range(len(chunks)):\n",
    "    new = chunks[i]\n",
    "    save_name = chunks_path+'%04d.%s'%(i,audiotype)\n",
    "    new.export(save_name, format=audiotype)\n",
    "    print('%04d'%i,len(new))\n",
    "print('保存完毕')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345ac8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "def main():\n",
    "    # 载入\n",
    "    name = '1.wav'\n",
    "    sound = AudioSegment.from_wav(name)\n",
    "    #sound = sound[:3*60*1000] # 如果文件较大，先取前3分钟测试，根据测试结果，调整参数\n",
    "    \n",
    "    # 设置参数\n",
    "    silence_thresh=-70      # 小于-70dBFS以下的为静默\n",
    "    min_silence_len=700     # 静默超过700毫秒则拆分\n",
    "    length_limit=60*1000    # 拆分后每段不得超过1分钟\n",
    "    abandon_chunk_len=500   # 放弃小于500毫秒的段\n",
    "    joint_silence_len=1300  # 段拼接时加入1300毫秒间隔用于断句\n",
    "    \n",
    "    # 将录音文件拆分成适合百度语音识别的大小\n",
    "    total = prepare_for_baiduaip(name,sound,silence_thresh,min_silence_len,length_limit,abandon_chunk_len,joint_silence_len)\n",
    "\n",
    "def prepare_for_baiduaip(name,sound,silence_thresh=-70,min_silence_len=700,length_limit=60*1000,abandon_chunk_len=500,joint_silence_len=1300):\n",
    "    '''\n",
    "    将录音文件拆分成适合百度语音识别的大小\n",
    "    百度目前免费提供1分钟长度的语音识别。\n",
    "    先按参数拆分录音，拆出来的每一段都小于1分钟。\n",
    "    然后将，时间过短的相邻段合并，合并后依旧不长于1分钟。\n",
    "\n",
    "    Args:\n",
    "        name: 录音文件名\n",
    "        sound: 录音文件数据\n",
    "        silence_thresh: 默认-70      # 小于-70dBFS以下的为静默\n",
    "        min_silence_len: 默认700     # 静默超过700毫秒则拆分\n",
    "        length_limit: 默认60*1000    # 拆分后每段不得超过1分钟\n",
    "        abandon_chunk_len: 默认500   # 放弃小于500毫秒的段\n",
    "        joint_silence_len: 默认1300  # 段拼接时加入1300毫秒间隔用于断句\n",
    "    Return:\n",
    "        total：返回拆分个数\n",
    "    '''\n",
    "\n",
    "    # 按句子停顿，拆分成长度不大于1分钟录音片段\n",
    "    print('开始拆分(如果录音较长，请耐心等待)\\n',' *'*30)\n",
    "    chunks = chunk_split_length_limit(sound,min_silence_len=min_silence_len,length_limit=length_limit,silence_thresh=silence_thresh)#silence time:700ms and silence_dBFS<-70dBFS\n",
    "    print('拆分结束，返回段数:',len(chunks),'\\n',' *'*30)\n",
    "\n",
    "    # 放弃长度小于0.5秒的录音片段\n",
    "    for i in list(range(len(chunks)))[::-1]:\n",
    "        if len(chunks[i])<=abandon_chunk_len:\n",
    "            chunks.pop(i)\n",
    "    print('取有效分段：',len(chunks))\n",
    "\n",
    "    # 时间过短的相邻段合并，单段不超过1分钟\n",
    "    chunks = chunk_join_length_limit(chunks,joint_silence_len=joint_silence_len,length_limit=length_limit)\n",
    "    print('合并后段数：',len(chunks))\n",
    "\n",
    "    # 保存前处理一下路径文件名\n",
    "    if not os.path.exists('./chunks'):os.mkdir('./chunks')\n",
    "    namef,namec = os.path.splitext(name)\n",
    "    namec = namec[1:]\n",
    "\n",
    "    # 保存所有分段\n",
    "    total = len(chunks)\n",
    "    for i in range(total):\n",
    "        new = chunks[i]\n",
    "        save_name = '%s_%04d.%s'%(namef,i,namec)\n",
    "        new.export('./chunks/'+save_name, format=namec)\n",
    "        # print('%04d'%i,len(new))\n",
    "    print('保存完毕')\n",
    "\n",
    "    return total\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def chunk_split_length_limit(chunk,min_silence_len=700,length_limit=60*1000,silence_thresh=-70):\n",
    "    '''\n",
    "    将声音文件按正常语句停顿拆分，并限定单句最长时间，返回结果为列表形式\n",
    "    Args:\n",
    "        chunk: 录音文件\n",
    "        min_silence_len: 拆分语句时，静默满足该长度，则拆分，默认0.7秒。\n",
    "        length_limit：拆分后单个文件长度不超过该值，默认1分钟。\n",
    "        silence_thresh：小于-70dBFS以下的为静默\n",
    "    Return:\n",
    "        done_chunks：拆分后的列表\n",
    "    '''\n",
    "    todo_arr = []   #待处理\n",
    "    done_chunks =[] #处理完\n",
    "    todo_arr.append([chunk,min_silence_len,silence_thresh])\n",
    "\n",
    "    while len(todo_arr)>0:\n",
    "        # 载入一个音频\n",
    "        temp_chunk,temp_msl,temp_st = todo_arr.pop(0)\n",
    "        # 不超长的，算是拆分成功\n",
    "        if len(temp_chunk)<length_limit:\n",
    "            done_chunks.append(temp_chunk)\n",
    "        else:\n",
    "            # 超长的，准备处理\n",
    "            # 配置参数\n",
    "            if temp_msl>100: # 优先缩小静默判断时常\n",
    "                temp_msl-=100\n",
    "            elif temp_st<-10: # 提升认为是静默的分贝数\n",
    "                temp_st+=10\n",
    "            else:\n",
    "                # 提升到极致还是不行的，输出异常\n",
    "                tempname = 'temp_%d.wav'%int(time.time())\n",
    "                chunk.export(tempname, format='wav')\n",
    "                print('万策尽。音长%d,静长%d分贝%d依旧超长,片段已保存至%s'%(len(temp_chunk),temp_msl,temp_st,tempname))\n",
    "                raise Exception\n",
    "            # 输出本次执行的拆分，所使用的参数\n",
    "            msg = '拆分中 音长,剩余[静长,分贝]:%d,%d[%d,%d]'%(len(temp_chunk),len(todo_arr),temp_msl,temp_st)\n",
    "            print(msg)\n",
    "            # 拆分\n",
    "            temp_chunks = split_on_silence(temp_chunk,min_silence_len=temp_msl,silence_thresh=temp_st)\n",
    "            # 拆分结果处理\n",
    "            doning_arr = [[c,temp_msl,temp_st] for c in temp_chunks]\n",
    "            todo_arr = doning_arr+todo_arr\n",
    "\n",
    "    return done_chunks\n",
    "\n",
    "\n",
    "\n",
    "def chunk_join_length_limit(chunks,joint_silence_len=1300,length_limit=60*1000):\n",
    "    '''\n",
    "    将声音文件合并，并限定单句最长时间，返回结果为列表形式\n",
    "    Args:\n",
    "        chunk: 录音文件\n",
    "        joint_silence_len: 合并时文件间隔，默认1.3秒。\n",
    "        length_limit：合并后单个文件长度不超过该值，默认1分钟。\n",
    "    Return:\n",
    "        adjust_chunks：合并后的列表\n",
    "    '''\n",
    "    # \n",
    "    silence = AudioSegment.silent(duration=joint_silence_len)\n",
    "    adjust_chunks=[]\n",
    "    temp = AudioSegment.empty()\n",
    "    for chunk in chunks:\n",
    "        length = len(temp)+len(silence)+len(chunk) # 预计合并后长度\n",
    "        if length<length_limit: # 小于1分钟，可以合并\n",
    "            temp+=silence+chunk\n",
    "        else: # 大于1分钟，先将之前的保存，重新开始累加\n",
    "            adjust_chunks.append(temp)\n",
    "            temp=chunk\n",
    "    else:\n",
    "        adjust_chunks.append(temp)\n",
    "    return adjust_chunks\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700238f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_WAV_PATH='/home/tx/AI/data/2019-M-CHN/wav/2019mchn_001.wav'\n",
    "y_predict=[]\n",
    "from pydub import AudioSegment\n",
    "from pydub.utils import make_chunks\n",
    "\n",
    "myaudio = AudioSegment.from_file(SAMPLE_WAV_PATH , \"wav\")\n",
    "chunk_length_ms = 10000 # 分块的毫秒数\n",
    "chunks = make_chunks(myaudio, chunk_length_ms) #将文件切割成10秒每块\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    chunk_name = \"output/tem.wav\".format(i)\n",
    "    print (\"exporting\", chunk_name)\n",
    "    chunk.export(chunk_name, format=\"wav\")#保存切割的音频到文件\n",
    "    \n",
    "    waveform, sample_rate = torchaudio.load(chunk_name)\n",
    "    num_channels, num_frames = waveform.numpy().shape\n",
    "    if num_channels == 1:\n",
    "#     plot_waveform(waveform,sample_rate)\n",
    "        predict = predict(waveform)\n",
    "    else: predict = predict(waveform[0])\n",
    "    print(f\"Predicted: {predict}.\")\n",
    "    y_predict.append(predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

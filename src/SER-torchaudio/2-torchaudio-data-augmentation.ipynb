{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用`torchaudio`的音频分类\n",
    "\n",
    "> 原文：<https://pytorch.org/tutorials/intermediate/speech_command_recognition_with_torchaudio.html>\n",
    "\n",
    "本教程将向您展示如何正确设置音频数据集的格式，然后在数据集上训练/测试音频分类器网络。\n",
    "\n",
    "Colab 提供了 GPU 选项。 在菜单选项卡中，选择“运行系统”，然后选择“更改运行系统类型”。 在随后的弹出窗口中，您可以选择 GPU。 更改之后，运行时应自动重新启动（这意味着来自已执行单元的信息会消失）。\n",
    "\n",
    "首先，让我们导入常见的 Torch 包，例如[`torchaudio`](https://github.com/pytorch/audio)，可以按照网站上的说明进行安装。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T07:41:42.11788Z",
     "iopub.status.busy": "2022-05-23T07:41:42.117617Z",
     "iopub.status.idle": "2022-05-23T07:41:43.623322Z",
     "shell.execute_reply": "2022-05-23T07:41:43.622141Z",
     "shell.execute_reply.started": "2022-05-23T07:41:42.117853Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import librosa\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchaudio.transforms as T\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "\n",
    "import IPython.display as ipd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解决jupyter 频繁挂掉服务#15错误\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "torch.cuda.empty_cache() # 清除gpu缓存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='0,1,2,3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T07:55:19.500072Z",
     "iopub.status.busy": "2022-05-23T07:55:19.499771Z",
     "iopub.status.idle": "2022-05-23T07:55:19.507031Z",
     "shell.execute_reply": "2022-05-23T07:55:19.505810Z",
     "shell.execute_reply.started": "2022-05-23T07:55:19.500037Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0 0.11.0 True cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(torch.__version__, torchaudio.__version__, torch.cuda.is_available(),device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('torch.FloatTensor', torch.Size([3, 4, 5]), 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.randn(3,4,5)\n",
    "tensor.type(),tensor.size(),tensor.dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=612\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['soundfile', 'sox_io']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchaudio.list_audio_backends()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们检查一下 CUDA GPU 是否可用，然后选择我们的设备。 在 GPU 上运行网络将大大减少训练/测试时间。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入数据集\n",
    "\n",
    "\n",
    "实际的加载和格式化步骤是在访问数据点时发生的，`torchaudio`负责将音频文件转换为张量。 如果想直接加载音频文件，可以使用`torchaudio.load()`。 它返回一个包含新创建的张量的元组以及音频文件的采样频率（`SpeechCommands`为 16kHz）。\n",
    "\n",
    "回到数据集，这里我们创建一个子类，将其分为标准训练，验证和测试子集。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Optional, Union\n",
    "import torchaudio\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "FOLDER_IN_ARCHIVE = \"TAL-SER\"\n",
    "EXCEPT_FOLDER = \"_background_noise_\"\n",
    "LABEL_FOLDER = 'label'\n",
    "EXTENDED_DATASET_FOLDER='EXTENDED'\n",
    "\n",
    "def pd_read_label(path:str):\n",
    "    label_df = pd.read_csv(os.path.join(path,LABEL_FOLDER,'label'),sep=\" \")\n",
    "    utt2gen_df = pd.read_csv(os.path.join(path,LABEL_FOLDER,'utt2gen'),sep=\" \",header=None,names=['id','sex'])\n",
    "\n",
    "    label_P_dict=label_df.set_index('id')['P'].to_dict()\n",
    "    label_A_dict=label_df.set_index('id')['A'].to_dict()\n",
    "    sex_dict=utt2gen_df.set_index('id')['sex'].to_dict()\n",
    "    return label_A_dict,label_P_dict,sex_dict\n",
    "\n",
    "def _load_list(root, *filenames):\n",
    "    output = []\n",
    "    for filename in filenames:\n",
    "        filepath = os.path.join(root,FOLDER_IN_ARCHIVE, filename)\n",
    "        with open(filepath) as fileobj:\n",
    "            output += [os.path.normpath(os.path.join(root, line.strip())) for line in fileobj]\n",
    "    return output\n",
    "\n",
    "def get_labels(P, A):\n",
    "    if  P>0:\n",
    "        if A>0:return '积极高唤醒'\n",
    "        else:return '消极高唤醒'\n",
    "    else:\n",
    "        if A<0:return '积极低唤醒'\n",
    "        else:return '消极低唤醒'\n",
    "        \n",
    "def split_talser_dataset_tolist(path:str):\n",
    "\n",
    "    label_df = pd.read_csv(path+\"label/label\",sep=\" \")\n",
    "    utt2gen_df = pd.read_csv(path+\"label/utt2gen\",sep=\" \",header=None,names=['id','sex'])\n",
    "    utt2spk_df = pd.read_csv(path+\"label/utt2spk\",sep=\" \",header=None,names=['id','speaker'])\n",
    "    wavscp_df = pd.read_csv(path+\"label/wavscp\",sep=\" \",header=None,names=['id','path'])\n",
    "    wavscp_df.sort_values('id', ignore_index=True,inplace =True)\n",
    "    data_df = pd.concat([label_df, utt2spk_df['speaker'], utt2gen_df['sex'],wavscp_df['path']], axis=1)\n",
    "    # data_df[\"path\"].replace(\".\\/S\", talser_path+\"S\", regex=True,inplace =True)\n",
    "    del label_df\n",
    "    del utt2gen_df\n",
    "    del utt2spk_df\n",
    "    del wavscp_df\n",
    "\n",
    "    def function(P, A):\n",
    "        if  P>0:\n",
    "            if A>0:\n",
    "                return 'AH'\n",
    "            else:\n",
    "                return 'PH'\n",
    "        else:\n",
    "            if A<0:\n",
    "                return 'AL'\n",
    "            else:\n",
    "                return 'PL'\n",
    "    data_df['emotion'] = data_df.apply(lambda x: function(x.P, x.A), axis = 1)\n",
    "\n",
    "\n",
    "    # data_df[\"path\"].replace(\".\\/S\", FOLDER_IN_ARCHIVE+\"/S\", regex=True,inplace=True)\n",
    "    # slow_tal_df = data_df[\"path\"].replace(\".\\/S\", FOLDER_IN_ARCHIVE+\"-SLOW/S\", regex=True)\n",
    "    # fast_tal_df = data_df[\"path\"].replace(\".\\/S\", FOLDER_IN_ARCHIVE+\"-FAST/S\", regex=True)\n",
    "    # data_df = pd.concat([tal_df, slow_tal_df, fast_tal_df], axis=0)\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train_df,test = train_test_split(data_df, test_size=0.4, random_state=612,\n",
    "                                    stratify=data_df[['emotion']])\n",
    "    val_df,test_df = train_test_split(test, test_size=0.5, random_state=612,\n",
    "                                    stratify=test[['emotion']])\n",
    "\n",
    "    test_df[\"path\"].replace(\".\\/S\", FOLDER_IN_ARCHIVE+\"/S\", regex=True ,inplace =True)\n",
    "    val_df[\"path\"].replace(\".\\/S\", FOLDER_IN_ARCHIVE+\"/S\", regex=True, inplace =True)\n",
    "    tal_df = train_df[\"path\"].replace(\".\\/S\", FOLDER_IN_ARCHIVE+\"/S\", regex=True)\n",
    "    slow_tal_df = train_df[\"path\"].replace(\".\\/S\", FOLDER_IN_ARCHIVE+\"-SLOW/S\", regex=True)\n",
    "    fast_tal_df = train_df[\"path\"].replace(\".\\/S\", FOLDER_IN_ARCHIVE+\"-FAST/S\", regex=True)\n",
    "    train_df = pd.concat([tal_df, slow_tal_df, fast_tal_df], axis=0)\n",
    "\n",
    "\n",
    "    train_df.to_csv(os.path.join(path,'talser_train_list.txt'),sep=' ',index=0,header=0)\n",
    "    val_df['path'].to_csv(os.path.join(path,'talser_validation_list.txt'),sep=' ',index=0,header=0)\n",
    "    test_df['path'].to_csv(os.path.join(path,'talser_testing_list.txt'),sep=' ',index=0,header=0)\n",
    "\n",
    "    \n",
    "class TALSER(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: Union[str, Path],\n",
    "        folder_in_archive: str = FOLDER_IN_ARCHIVE,\n",
    "        subset: Optional[str] = None,\n",
    "    ) -> None:\n",
    "        assert subset is None or subset in [\"training\", \"validation\", \"testing\"], (\n",
    "            \"When `subset` not None, it must take a value from \" + \"{'training', 'validation', 'testing'}.\"\n",
    "        )\n",
    "        # Get string representation of 'root' in case Path object is passed\n",
    "        root = os.fspath(root)\n",
    "        # self._path = os.path.join(root, folder_in_archive)\n",
    "        self._path = root\n",
    "        self.label_A_dict, self.label_P_dict, self.sex_dict=pd_read_label(self._path)\n",
    "        split_talser_dataset_tolist(self._path)\n",
    "        if subset =='extended':\n",
    "            self._walker = _load_list(self._path, EXTENDED_DATASET_FOLDER)\n",
    "        if subset == \"validation\":\n",
    "            self._walker = _load_list(self._path, \"talser_validation_list.txt\")\n",
    "        elif subset == \"testing\":\n",
    "            self._walker = _load_list(self._path, \"tal_ser_testing_list.txt\")\n",
    "        elif subset == \"training\":\n",
    "            excludes = set(_load_list(self._path, \"talser_validation_list.txt\", \"talser_testing_list.txt\"))\n",
    "            walker = sorted(str(p) for p in Path(self._path).glob(\"*/*.wav\"))\n",
    "            self._walker = [\n",
    "                w\n",
    "                for w in walker\n",
    "                if EXCEPT_FOLDER not in w and os.path.normpath(w) not in excludes\n",
    "            ]\n",
    "        else:\n",
    "            walker = sorted(str(p) for p in Path(self._path).glob(\"*/*.wav\"))\n",
    "            self._walker = [w for w in walker if EXCEPT_FOLDER not in w]\n",
    "\n",
    "\n",
    "    def __getitem__(self, n: int) -> Tuple[Tensor, int, str, int, int,str,str,int]:\n",
    "        \"\"\"Load the n-th sample from the dataset.\n",
    "\n",
    "        Args:\n",
    "            n (int): The index of the sample to be loaded\n",
    "        Returns:\n",
    "            (Tensor, int, str, str, int):\n",
    "        \"\"\"\n",
    "        filepath = self._walker[n]\n",
    "        relpath = os.path.relpath(filepath, self._path)\n",
    "        speaker_id, filename = os.path.split(relpath)\n",
    "        utterance_number,_= os.path.splitext(filename)# 分离文件名和拓展名\n",
    "        utterance_number = int(utterance_number)\n",
    "        P=self.label_P_dict[utterance_number]\n",
    "        A=self.label_A_dict[utterance_number]\n",
    "        sex=self.sex_dict[utterance_number]\n",
    "        utterance_number = int(utterance_number)\n",
    "        labels=get_labels(P,A)\n",
    "        # Load audio\n",
    "        waveform, sample_rate = torchaudio.load(filepath)\n",
    "        return waveform, sample_rate, labels, P, A, sex, speaker_id, utterance_number\n",
    "\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self._walker)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %xmode Plain\n",
    "# %pdb on\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T07:42:01.604812Z",
     "iopub.status.busy": "2022-05-23T07:42:01.604403Z",
     "iopub.status.idle": "2022-05-23T07:43:31.395838Z",
     "shell.execute_reply": "2022-05-23T07:43:31.394832Z",
     "shell.execute_reply.started": "2022-05-23T07:42:01.604764Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/label/label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-af078d4b759c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Create training and testing split of the data. We do not use validation in this tutorial.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mtrain_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSubsetSC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mtest_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSubsetSC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"testing\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSubsetSC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"validation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-af078d4b759c>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, subset)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mSubsetSC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTALSER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mload_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-49bf7c94ae6e>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, folder_in_archive, subset)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;31m# self._path = os.path.join(root, folder_in_archive)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_A_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_P_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msex_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd_read_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0msplit_talser_dataset_tolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msubset\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;34m'extended'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-49bf7c94ae6e>\u001b[0m in \u001b[0;36mpd_read_label\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpd_read_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mlabel_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLABEL_FOLDER\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mutt2gen_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLABEL_FOLDER\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'utt2gen'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'sex'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2008\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/label/label'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "class SubsetSC(TALSER): \n",
    "    def __init__(self, subset: str = None):\n",
    "        super().__init__(\"../data/\")\n",
    "\n",
    "        def load_list(filename):\n",
    "            filepath = os.path.join(self._path, filename)\n",
    "            with open(filepath) as fileobj:\n",
    "                return [os.path.join(self._path, line.strip()) for line in fileobj]\n",
    "\n",
    "        if subset == \"validation\":\n",
    "            self._walker = load_list(\"talser_validation_list.txt\")\n",
    "        elif subset == \"testing\":\n",
    "            self._walker = load_list(\"talser_testing_list.txt\")\n",
    "        elif subset == \"training\":\n",
    "            self._walker = load_list(\"talser_train_list.txt\")+load_list(\"talser_validation_list.txt\")\n",
    "#             excludes = load_list(\"talser_validation_list.txt\") + load_list(\"talser_testing_list.txt\")\n",
    "#             excludes = set(excludes)\n",
    "#             self._walker = [w for w in self._walker if w not in excludes]\n",
    "            \n",
    "# Create training and testing split of the data. We do not use validation in this tutorial.\n",
    "train_set = SubsetSC(\"training\")\n",
    "test_set = SubsetSC(\"testing\")\n",
    "val_set=SubsetSC(\"validation\")\n",
    "waveform, sample_rate, labels, P, A, sex, speaker_id, utterance_number = train_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([[ 0.0467,  0.5343,  0.7824,  ..., -0.0682,  0.0869,  0.1695]]),\n",
       "  16000,\n",
       "  '消极低唤醒',\n",
       "  -1.342194963,\n",
       "  0.539038381,\n",
       "  'male',\n",
       "  'SER005',\n",
       "  5471),\n",
       " 3350,\n",
       " 838,\n",
       " 838,\n",
       " 5026)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0],train_set.__len__(),test_set.__len__(),val_set.__len__(),(train_set.__len__()+test_set.__len__()+val_set.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-23T07:43:31.39766Z",
     "iopub.status.busy": "2022-05-23T07:43:31.397454Z",
     "iopub.status.idle": "2022-05-23T07:43:31.849857Z",
     "shell.execute_reply": "2022-05-23T07:43:31.849188Z",
     "shell.execute_reply.started": "2022-05-23T07:43:31.397634Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of waveform: torch.Size([1, 160000])\n",
      "Sample rate of waveform: 16000\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of waveform: {}\".format(waveform.size()))\n",
    "print(\"Sample rate of waveform: {}\".format(sample_rate))\n",
    "\n",
    "# plt.plot(waveform.t().numpy());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "让我们找到数据集中可用的标签列表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T13:16:17.944135Z",
     "iopub.status.busy": "2022-04-25T13:16:17.943908Z",
     "iopub.status.idle": "2022-04-25T13:17:15.671779Z",
     "shell.execute_reply": "2022-04-25T13:17:15.670851Z",
     "shell.execute_reply.started": "2022-04-25T13:16:17.944107Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = sorted(list(set(datapoint[2] for datapoint in train_set)))\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform_first, *_ = train_set[0]\n",
    "ipd.Audio(waveform_first.numpy(), rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T13:17:15.674821Z",
     "iopub.status.busy": "2022-04-25T13:17:15.674595Z",
     "iopub.status.idle": "2022-04-25T13:17:15.685231Z",
     "shell.execute_reply": "2022-04-25T13:17:15.684032Z",
     "shell.execute_reply.started": "2022-04-25T13:17:15.674793Z"
    }
   },
   "outputs": [],
   "source": [
    "waveform_second, *_ = train_set[1]\n",
    "ipd.Audio(waveform_second.numpy(), rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T13:17:15.686901Z",
     "iopub.status.busy": "2022-04-25T13:17:15.686673Z",
     "iopub.status.idle": "2022-04-25T13:17:15.696816Z",
     "shell.execute_reply": "2022-04-25T13:17:15.695753Z",
     "shell.execute_reply.started": "2022-04-25T13:17:15.686859Z"
    }
   },
   "outputs": [],
   "source": [
    "waveform_last, *_ = train_set[-1]\n",
    "ipd.Audio(waveform_last.numpy(), rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 格式化数据\n",
    "\n",
    "这是将转换应用于数据的好地方。 对于波形，我们对音频进行下采样以进行更快的处理，而不会损失太多的分类能力。\n",
    "\n",
    "我们无需在此应用其他转换。 对于某些数据集，通常必须通过沿通道维度取平均值或仅保留其中一个通道来减少通道数量（例如，从立体声到单声道）。 由于`talser`使用单个通道进行音频，因此此处不需要。\n",
    "其他变换 https://www.kaggle.com/code/elsash/i-o-torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T13:17:15.698414Z",
     "iopub.status.busy": "2022-04-25T13:17:15.698184Z",
     "iopub.status.idle": "2022-04-25T13:17:15.716268Z",
     "shell.execute_reply": "2022-04-25T13:17:15.715441Z",
     "shell.execute_reply.started": "2022-04-25T13:17:15.698386Z"
    }
   },
   "outputs": [],
   "source": [
    "new_sample_rate = 8000\n",
    "transform = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=new_sample_rate)\n",
    "transformed = transform(waveform)\n",
    "\n",
    "ipd.Audio(transformed.numpy(), rate=new_sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "我们使用标签列表中的每个索引对每个标签进行编码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "execution": {
     "iopub.execute_input": "2022-04-25T13:17:15.718506Z",
     "iopub.status.busy": "2022-04-25T13:17:15.717869Z",
     "iopub.status.idle": "2022-04-25T13:17:15.72875Z",
     "shell.execute_reply": "2022-04-25T13:17:15.727793Z",
     "shell.execute_reply.started": "2022-04-25T13:17:15.718458Z"
    }
   },
   "outputs": [],
   "source": [
    "def label_to_index(word):\n",
    "    # Return the position of the word in labels\n",
    "    return torch.tensor(labels.index(word))\n",
    "\n",
    "def index_to_label(index):\n",
    "    # Return the word corresponding to the index in labels\n",
    "    # This is the inverse of label_to_index\n",
    "    return labels[index]\n",
    "\n",
    "word_start = \"积极高唤醒\"\n",
    "index = label_to_index(word_start)\n",
    "word_recovered = index_to_label(index)\n",
    "\n",
    "print(word_start, \"-->\", index, \"-->\", word_recovered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "为了将由录音和语音构成的数据点列表转换为该模型的两个成批张量，我们实现了整理函数，PyTorch `DataLoader`使用了该函数，允许我们分批迭代数据集。 有关使用整理函数的更多信息，请参见[文档](https://pytorch.org/docs/stable/data.html#working-with-collate-fn)。\n",
    "\n",
    "在整理函数中，我们还应用了重采样和文本编码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T13:48:48.259208Z",
     "iopub.status.busy": "2022-04-25T13:48:48.257058Z",
     "iopub.status.idle": "2022-04-25T13:48:48.273551Z",
     "shell.execute_reply": "2022-04-25T13:48:48.27206Z",
     "shell.execute_reply.started": "2022-04-25T13:48:48.259145Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def pad_sequence(batch):\n",
    "    # Make all tensor in a batch the same length by padding with zeros\n",
    "    batch = [item.t() for item in batch]\n",
    "    batch = torch.nn.utils.rnn.pad_sequence(batch, batch_first=True, padding_value=0.)\n",
    "    return batch.permute(0, 2, 1)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # A data tuple has the form:\n",
    "    tensors, targets = [], []\n",
    "\n",
    "    # Gather in lists, and encode labels as indices\n",
    "    for waveform, _, label, *_ in batch:\n",
    "        tensors += [waveform]\n",
    "        targets += [label_to_index(label)]\n",
    "    \n",
    "    # Group the list of tensors into a batched tensor\n",
    "    tensors = pad_sequence(tensors)\n",
    "    targets = torch.stack(targets)\n",
    "    return tensors, targets\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "if device == \"cuda\":\n",
    "    num_workers = 4\n",
    "    pin_memory = True\n",
    "    \n",
    "else:\n",
    "    num_workers = 0\n",
    "    pin_memory = False\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    ")\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义网络\n",
    "\n",
    "在本教程中，我们将使用卷积神经网络来处理原始音频数据。 通常，更高级的转换将应用于音频数据，但是 CNN 可以用于准确处理原始数据。 具体架构是根据[本文](https://arxiv.org/pdf/1610.00087.pdf)中描述的 M5 网络架构建模的。 模型处理原始音频数据的一个重要方面是其第一层过滤器的接收范围。 我们模型的第一个过滤器长度为 80，因此在处理以 8kHz 采样的音频时，接收场约为 10ms（而在 4kHz 时约为 20ms）。 此大小类似于语音处理应用，该应用通常使用 20ms 到 40ms 的接收域。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T13:17:15.766498Z",
     "iopub.status.busy": "2022-04-25T13:17:15.765993Z",
     "iopub.status.idle": "2022-04-25T13:17:15.790975Z",
     "shell.execute_reply": "2022-04-25T13:17:15.789982Z",
     "shell.execute_reply.started": "2022-04-25T13:17:15.766444Z"
    }
   },
   "outputs": [],
   "source": [
    "class M5(nn.Module):\n",
    "    def __init__(self, n_input=1, n_output=4, stride=16, n_channel=32):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(n_input, n_channel, kernel_size=80, stride=stride)\n",
    "        self.bn1 = nn.BatchNorm1d(n_channel)\n",
    "        self.pool1 = nn.MaxPool1d(4)\n",
    "        self.conv2 = nn.Conv1d(n_channel, n_channel, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm1d(n_channel)\n",
    "        self.pool2 = nn.MaxPool1d(4)\n",
    "        self.conv3 = nn.Conv1d(n_channel, 2 * n_channel, kernel_size=3)\n",
    "        self.bn3 = nn.BatchNorm1d(2 * n_channel)\n",
    "        self.pool3 = nn.MaxPool1d(4)\n",
    "        self.conv4 = nn.Conv1d(2 * n_channel, 2 * n_channel, kernel_size=3)\n",
    "        self.bn4 = nn.BatchNorm1d(2 * n_channel)\n",
    "        self.pool4 = nn.MaxPool1d(4)\n",
    "        self.fc1 = nn.Linear(2 * n_channel, n_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(self.bn2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(self.bn3(x))\n",
    "        x = self.pool3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(self.bn4(x))\n",
    "        x = self.pool4(x)\n",
    "        x = F.avg_pool1d(x, x.shape[-1])\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.fc1(x)\n",
    "        return F.log_softmax(x, dim=2)\n",
    "\n",
    "model = M5(n_input=transformed.shape[0], n_output=len(labels))\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    gpus = [0, 1, 2, 3]\n",
    "    torch.cuda.set_device('cuda:{}'.format(gpus[0]))\n",
    "    model = torch.nn.DataParallel(model.to(device), device_ids=gpus,output_device=gpus[0])\n",
    "else:\n",
    "    model.to(device)    \n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "n = count_parameters(model)\n",
    "print(\"Number of parameters: %s\" % n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们将使用与本文相同的优化技术，将权重衰减设置为 0.0001 的 Adam 优化器。 首先，我们将以 0.01 的学习率进行训练，但是在 20 个周期后的训练过程中，我们将使用`scheduler`将其降低到 0.001。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pad_sequence(batch):\n",
    "    # Make all tensor in a batch the same length by padding with zeros\n",
    "    batch = [item.t() for item in batch]\n",
    "    batch = torch.nn.utils.rnn.pad_sequence(batch, batch_first=True, padding_value=0.)\n",
    "    return batch.permute(0, 2, 1)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # A data tuple has the form:\n",
    "    tensors, targets = [], []\n",
    "\n",
    "    # Gather in lists, and encode labels as indices\n",
    "    for waveform, _, label, *_ in batch:\n",
    "        tensors += [waveform]\n",
    "        targets += [label_to_index(label)]\n",
    "    \n",
    "    # Group the list of tensors into a batched tensor\n",
    "    tensors = pad_sequence(tensors)\n",
    "    targets = torch.stack(targets)\n",
    "    return tensors, targets\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "if device == \"cuda\":\n",
    "    num_workers = 4\n",
    "    pin_memory = True\n",
    "    \n",
    "else:\n",
    "    num_workers = 0\n",
    "    pin_memory = False\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    ")\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T13:17:15.793879Z",
     "iopub.status.busy": "2022-04-25T13:17:15.793654Z",
     "iopub.status.idle": "2022-04-25T13:17:15.805679Z",
     "shell.execute_reply": "2022-04-25T13:17:15.804595Z",
     "shell.execute_reply.started": "2022-04-25T13:17:15.793852Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=0.0001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)  # reduce the learning after 20 epochs by a factor of 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 训练和测试网络\n",
    "\n",
    "现在，我们定义一个训练函数，它将训练数据输入模型中，并执行反向传播和优化步骤。 对于训练，我们将使用的损失是负对数可能性。 然后，在每个周期之后将对网络进行测试，以查看训练期间准确率如何变化。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T13:17:15.80749Z",
     "iopub.status.busy": "2022-04-25T13:17:15.807211Z",
     "iopub.status.idle": "2022-04-25T13:17:15.82046Z",
     "shell.execute_reply": "2022-04-25T13:17:15.819728Z",
     "shell.execute_reply.started": "2022-04-25T13:17:15.807453Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, epoch, log_interval):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        # apply transform and model on whole batch directly on device\n",
    "        # print(f'data before transform:{data.cpu().numpy().shape}')\n",
    "        data = transform(data)\n",
    "        # print(f'data after transform:{data.cpu().numpy().shape}')\n",
    "        output = model(data)\n",
    "        pred = get_likely_index(output)\n",
    "        correct += number_of_correct(pred, target)\n",
    "        # negative log-likelihood for a tensor of size (batch x 1 x n_output)\n",
    "        loss = F.nll_loss(output.squeeze(), target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "   #update progress bar\n",
    "#     pbar.update(pbar_update)\n",
    "    # print training stats\n",
    "    if batch_idx % log_interval == 0:\n",
    "        print(f\"Train Epoch: {epoch}    [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]  Loss: {loss.item():.6f}   Accuracy: {correct}/{len(train_loader.dataset)} ({100. * correct / len(train_loader.dataset):.0f}%)\")\n",
    "        # record loss\n",
    "        losses.append(loss.item())\n",
    "        # record training Accuracy\n",
    "    train_acc.append(correct / len(train_loader.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们有了训练函数，我们需要制作一个用于测试网络准确率的函数。 我们将模型设置为`eval()`模式，然后对测试数据集进行推断。 调用`eval()`将网络中所有模块中的训练变量设置为`false`。 某些层（例如批量归一化层和丢弃层）在训练期间的行为会有所不同，因此此步骤对于获取正确的结果至关重要。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T13:17:15.822464Z",
     "iopub.status.busy": "2022-04-25T13:17:15.821746Z",
     "iopub.status.idle": "2022-04-25T13:17:15.841667Z",
     "shell.execute_reply": "2022-04-25T13:17:15.840809Z",
     "shell.execute_reply.started": "2022-04-25T13:17:15.822415Z"
    }
   },
   "outputs": [],
   "source": [
    "def number_of_correct(pred, target):\n",
    "    # count number of correct predictions\n",
    "    return pred.squeeze().eq(target).sum().item()\n",
    "\n",
    "def get_likely_index(tensor):\n",
    "    # find most likely label index for each element in the batch\n",
    "    return tensor.argmax(dim=-1)\n",
    "\n",
    "def test(model, epoch):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        # apply transform and model on whole batch directly on device\n",
    "        data = transform(data)\n",
    "        output = model(data)\n",
    "        pred = get_likely_index(output)\n",
    "        correct += number_of_correct(pred, target)\n",
    "\n",
    "#     update progress bar\n",
    "#     pbar.update(pbar_update)\n",
    "#     print training stats\n",
    "    print(f\" Test Epoch: {epoch}  Accuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset):.0f}%) \")\n",
    "    # test acc\n",
    "    test_acc.append(correct / len(test_loader.dataset))\n",
    "    # 保存模型\n",
    "#     torch.save(model,'model_{}.pth'.format(epoch+1))\n",
    "#     print(\"第{}轮模型训练数据已保存\".format(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(model, epoch):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    \n",
    "    for data, target in val_loader:\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        # apply transform and model on whole batch directly on device\n",
    "        data = transform(data)\n",
    "        output = model(data)\n",
    "        pred = get_likely_index(output)\n",
    "        correct += number_of_correct(pred, target)\n",
    "\n",
    "#     update progress bar\n",
    "#     pbar.update(pbar_update)\n",
    "    # print training stats\n",
    "    print(f\" val Epoch: {epoch}  Accuracy: {correct}/{len(val_loader.dataset)} ({100. * correct / len(val_loader.dataset):.0f}%) \")\n",
    "    # test acc\n",
    "    val_acc.append(correct / len(val_loader.dataset))\n",
    "    # 保存模型\n",
    "    torch.save(model,'output/checkpoints/model_{}.pth'.format(val_acc))\n",
    "#     print(\"第{}轮模型训练数据已保存\".format(epoch+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，我们可以训练和测试网络。 我们将训练网络十个周期，然后降低学习率，再训练十个周期。 在每个周期之后将对网络进行测试，以查看训练过程中准确率如何变化。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T13:17:15.843493Z",
     "iopub.status.busy": "2022-04-25T13:17:15.842658Z",
     "iopub.status.idle": "2022-04-25T13:21:01.057953Z",
     "shell.execute_reply": "2022-04-25T13:21:01.055864Z",
     "shell.execute_reply.started": "2022-04-25T13:17:15.843454Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log_interval = 1\n",
    "n_epoch = 50\n",
    "\n",
    "\n",
    "print('Start Training...')\n",
    "from datetime import datetime\n",
    "nowtime = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "print('========='*8 + '%s'%nowtime)\n",
    "\n",
    "pbar_update = 1 \n",
    "losses = []\n",
    "test_acc=[]\n",
    "train_acc=[]\n",
    "val_acc=[]\n",
    "# The transform needs to live on the same device as the model and the data.\n",
    "transform = transform.to(device)\n",
    "with tqdm(total=n_epoch) as pbar:\n",
    "    for epoch in range(1, n_epoch + 1):\n",
    "        train(model, epoch, log_interval)\n",
    "        test(model, epoch)\n",
    "        val(model,epoch)\n",
    "        scheduler.step()\n",
    "        pbar.update(pbar_update)    \n",
    "dfhistory=pd.DataFrame(data=[losses,test_acc,train_acc,val_acc],index = ['losses','test_acc','train_acc','val_acc']).T  \n",
    "# 保存训练日志\n",
    "dfhistory.to_csv(f'output/train_test_history.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the training loss versus the number of iteration.\n",
    "plt.plot(losses)\n",
    "plt.title(\"training loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_acc,label='test')\n",
    "plt.plot(train_acc,label='train')\n",
    "plt.plot(val_acc,label='val')\n",
    "plt.title(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "50个周期后，测试集的网络准确率应超过 19%，而 50 个周期后，网络应达到 91%。 让我们看一下训练集中的最后几个数据，看看模型是如何做到的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T13:21:01.061731Z",
     "iopub.status.busy": "2022-04-25T13:21:01.060517Z",
     "iopub.status.idle": "2022-04-25T13:21:01.077458Z",
     "shell.execute_reply": "2022-04-25T13:21:01.076468Z",
     "shell.execute_reply.started": "2022-04-25T13:21:01.061688Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(tensor):\n",
    "    # Use the model to predict the label of the waveform\n",
    "    tensor = tensor.to(device)\n",
    "    tensor = transform(tensor)\n",
    "    tensor = model(tensor.unsqueeze(0))\n",
    "    tensor = get_likely_index(tensor)\n",
    "    tensor = index_to_label(tensor.squeeze())\n",
    "    return tensor\n",
    "\n",
    "waveform, sample_rate, label, P, A, sex, speaker_id, utterance_number= train_set[-1]\n",
    "ipd.Audio(waveform.numpy(), rate=sample_rate)\n",
    "\n",
    "print(f\"Expected: {label}. Predicted: {predict(waveform)}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果有一个示例，我们来寻找一个分类错误的示例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T13:21:01.079023Z",
     "iopub.status.busy": "2022-04-25T13:21:01.078788Z",
     "iopub.status.idle": "2022-04-25T13:21:01.09645Z",
     "shell.execute_reply": "2022-04-25T13:21:01.095603Z",
     "shell.execute_reply.started": "2022-04-25T13:21:01.078993Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, (waveform, sample_rate, label, *_) in enumerate(test_set):\n",
    "    output = predict(waveform)\n",
    "    if output != label:\n",
    "        ipd.Audio(waveform.numpy(), rate=sample_rate)\n",
    "        print(f\"Data point #{i}. Expected: {label}. Predicted: {output}.\")\n",
    "        break\n",
    "else:\n",
    "    print(\"All examples in this dataset were correctly classified!\")\n",
    "    print(\"In this case, let's just look at the last data point\")\n",
    "    ipd.Audio(waveform.numpy(), rate=sample_rate)\n",
    "    print(f\"Data point #{i}. Expected: {label}. Predicted: {output}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制混淆矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true=[]\n",
    "y_pred=[]\n",
    "for i, (waveform, sample_rate, label, *_) in enumerate(test_set):\n",
    "    output = predict(waveform)\n",
    "    if output != label:\n",
    "        ipd.Audio(waveform.numpy(), rate=sample_rate)\n",
    "#         print(f\"Data point #{i}. Expected: {label}. Predicted: {output}.\")\n",
    "        y_pred.append(output)\n",
    "        y_true.append(label)\n",
    "if len(y_pred)==0:\n",
    "    print(\"All examples in this dataset were correctly classified!\")\n",
    "    print(\"In this case, let's just look at the last data point\")\n",
    "    ipd.Audio(waveform.numpy(), rate=sample_rate)\n",
    "    print(f\"Data point #{i}. Expected: {label}. Predicted: {output}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "rc = {'axes.unicode_minus': False}\n",
    "sns.set(context='notebook', style='ticks', font='SimHei', rc=rc)\n",
    "C=confusion_matrix(y_true, y_pred, labels=labels)\n",
    "df=pd.DataFrame(C,index=labels,columns=labels)\n",
    "f,ax=plt.subplots()\n",
    "print(df) #打印出来看看\n",
    "sns.heatmap(df,annot=True,ax=ax) #画热力图\n",
    "ax.set_title('confusion matrix') #标题\n",
    "ax.set_xlabel('predict') #x轴\n",
    "ax.set_ylabel('true') #y轴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 长音频预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_WAV_PATH='F://ZLQ//TVA2022//VIDEO50/2019mchn_1.wav'\n",
    "y_predict=[]\n",
    "from pydub import AudioSegment\n",
    "from pydub.utils import make_chunks\n",
    "\n",
    "myaudio = AudioSegment.from_file(SAMPLE_WAV_PATH , \"wav\")\n",
    "chunk_length_ms = 10000 # 分块的毫秒数\n",
    "chunks = make_chunks(myaudio, chunk_length_ms) #将文件切割成1秒每块\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    chunk_name = \"tem.wav\".format(i)\n",
    "    print (\"exporting\", chunk_name)\n",
    "    chunk.export(chunk_name, format=\"wav\")#保存切割的音频到文件\n",
    "    waveform, sample_rate = torchaudio.load(chunk_name)\n",
    "#     plot_waveform(waveform,sample_rate)\n",
    "    predict = predict(waveform)\n",
    "    print(f\"Predicted: {predict}.\")\n",
    "    y_predict.append(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = torchaudio.info(SAMPLE_WAV_PATH)\n",
    "print(metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sox\n",
    "!sox SAMPLE_WAV_PATH './samplewav' trim 0 10 : newfile : restart\n",
    "# 比如执行 sox ~/Music/PI_ringtone.mp3  ~/Music/PI_ringtone.mp3 trim 0 15.5 : newfile : restart \n",
    "# 会在 ~/Music/ 目录下生成名称前缀为 PI_ringtone、 格式为 .mp3、时长为 15.5 秒的若干个音频片段 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myaudio = AudioSegment.from_file(SAMPLE_WAV_PATH , \"wav\")\n",
    "chunk_length_ms = 1000 # 分块的毫秒数\n",
    "chunks = make_chunks(myaudio, chunk_length_ms) #将文件切割成1秒每块\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    try:\n",
    "        wav_info = sox.file_info.info(wav_path)  # TODO\n",
    "    except sox.core.SoxiError as e:\n",
    "        print('Invalid wav file: {}, exception raised ( {} ), maybe because invalid RIFF header'.format(wav_path, e))\n",
    "    # wav_info['silent'] == True 认为该音频silent\n",
    "    if wav_info['silent'] != False:\n",
    "        print('Invalid wav file: {}, silent is {}'.format(wav_path, wav_info['silent']))\n",
    "\n",
    "    waveform, sample_rate = torchaudio.load(filepath)\n",
    "    ipd.Audio(waveform.numpy(), rate=sample_rate)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 其他模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter\n",
    "\n",
    "\n",
    "class Res2Conv1dReluBn(nn.Module):\n",
    "    def __init__(self, channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False, scale=4):\n",
    "        super().__init__()\n",
    "        assert channels % scale == 0, \"{} % {} != 0\".format(channels, scale)\n",
    "        self.scale = scale\n",
    "        self.width = channels // scale\n",
    "        self.nums = scale if scale == 1 else scale - 1\n",
    "\n",
    "        self.convs = []\n",
    "        self.bns = []\n",
    "        for i in range(self.nums):\n",
    "            self.convs.append(nn.Conv1d(self.width, self.width, kernel_size, stride, padding, dilation, bias=bias))\n",
    "            self.bns.append(nn.BatchNorm1d(self.width))\n",
    "        self.convs = nn.ModuleList(self.convs)\n",
    "        self.bns = nn.ModuleList(self.bns)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = []\n",
    "        spx = torch.split(x, self.width, 1)\n",
    "        for i in range(self.nums):\n",
    "            if i == 0:\n",
    "                sp = spx[i]\n",
    "            else:\n",
    "                sp = sp + spx[i]\n",
    "            # Order: conv -> relu -> bn\n",
    "            sp = self.convs[i](sp)\n",
    "            sp = self.bns[i](F.relu(sp))\n",
    "            out.append(sp)\n",
    "        if self.scale != 1:\n",
    "            out.append(spx[self.nums])\n",
    "        out = torch.cat(out, dim=1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Conv1dReluBn(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding, dilation, bias=bias)\n",
    "        self.bn = nn.BatchNorm1d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.bn(F.relu(self.conv(x)))\n",
    "\n",
    "\n",
    "class SE_Connect(nn.Module):\n",
    "    def __init__(self, channels, s=2):\n",
    "        super().__init__()\n",
    "        assert channels % s == 0, \"{} % {} != 0\".format(channels, s)\n",
    "        self.linear1 = nn.Linear(channels, channels // s)\n",
    "        self.linear2 = nn.Linear(channels // s, channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x.mean(dim=2)\n",
    "        out = F.relu(self.linear1(out))\n",
    "        out = torch.sigmoid(self.linear2(out))\n",
    "        out = x * out.unsqueeze(2)\n",
    "        return out\n",
    "\n",
    "\n",
    "def SE_Res2Block(channels, kernel_size, stride, padding, dilation, scale):\n",
    "    return nn.Sequential(\n",
    "        Conv1dReluBn(channels, channels, kernel_size=1, stride=1, padding=0),\n",
    "        Res2Conv1dReluBn(channels, kernel_size, stride, padding, dilation, scale=scale),\n",
    "        Conv1dReluBn(channels, channels, kernel_size=1, stride=1, padding=0),\n",
    "        SE_Connect(channels)\n",
    "    )\n",
    "\n",
    "\n",
    "class AttentiveStatsPool(nn.Module):\n",
    "    def __init__(self, in_dim, bottleneck_dim):\n",
    "        super().__init__()\n",
    "        # Use Conv1d with stride == 1 rather than Linear, then we don't need to transpose inputs.\n",
    "        self.linear1 = nn.Conv1d(in_dim, bottleneck_dim, kernel_size=1)  # equals W and b in the paper\n",
    "        self.linear2 = nn.Conv1d(bottleneck_dim, in_dim, kernel_size=1)  # equals V and k in the paper\n",
    "\n",
    "    def forward(self, x):\n",
    "        # DON'T use ReLU here! In experiments, I find ReLU hard to converge.\n",
    "        alpha = torch.tanh(self.linear1(x))\n",
    "        alpha = torch.softmax(self.linear2(alpha), dim=2)\n",
    "        mean = torch.sum(alpha * x, dim=2)\n",
    "        residuals = torch.sum(alpha * x ** 2, dim=2) - mean ** 2\n",
    "        std = torch.sqrt(residuals.clamp(min=1e-9))\n",
    "        return torch.cat([mean, std], dim=1)\n",
    "\n",
    "\n",
    "class EcapaTdnn(nn.Module):\n",
    "#     def __init__(self, n_input=1, n_output=4, stride=16, n_channel=32):\n",
    "    def __init__(self, num_classes, input_size=80, channels=512, embd_dim=192):\n",
    "        super().__init__()\n",
    "        self.layer1 = Conv1dReluBn(input_size, channels, kernel_size=5, padding=2, dilation=1)\n",
    "        self.layer2 = SE_Res2Block(channels, kernel_size=3, stride=1, padding=2, dilation=2, scale=8)\n",
    "        self.layer3 = SE_Res2Block(channels, kernel_size=3, stride=1, padding=3, dilation=3, scale=8)\n",
    "        self.layer4 = SE_Res2Block(channels, kernel_size=3, stride=1, padding=4, dilation=4, scale=8)\n",
    "\n",
    "        cat_channels = channels * 3\n",
    "        out_channels = cat_channels * 2\n",
    "        self.conv = nn.Conv1d(cat_channels, cat_channels, kernel_size=1)\n",
    "        self.pooling = AttentiveStatsPool(cat_channels, 128)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.linear = nn.Linear(out_channels, embd_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(embd_dim)\n",
    "        self.fc = nn.Linear(embd_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = self.layer1(x)\n",
    "        out2 = self.layer2(out1) + out1\n",
    "        out3 = self.layer3(out1 + out2) + out1 + out2\n",
    "        out4 = self.layer4(out1 + out2 + out3) + out1 + out2 + out3\n",
    "\n",
    "        out = torch.cat([out2, out3, out4], dim=1)\n",
    "        out = F.relu(self.conv(out))\n",
    "        out = self.bn1(self.pooling(out))\n",
    "        out = self.bn2(self.linear(out))\n",
    "        return out\n",
    "\n",
    "model = EcapaTdnn(num_classes=len(labels),input_size=transformed.shape[0])\n",
    "if torch.cuda.device_count() > 1:\n",
    "#     torch.distributed.init_process_group(backend='gloo')\n",
    "    model = nn.DataParallel(model,device_ids=[0,1,2,3],output_device=0)\n",
    "\n",
    "model.to(device)    \n",
    "    \n",
    "torch.save(model,'EcapaTdnn.pt')\n",
    "print(model)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "n = count_parameters(model)\n",
    "print(\"Number of parameters: %s\" % n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "在本教程中，我们使用了`torchaudio`来加载数据集并对信号进行重新采样。 然后，我们定义了经过训练的神经网络，以识别给定命令。 还有其他数据预处理方法，例如找到梅尔频率倒谱系数（MFCC），可以减小数据集的大小。 此变换也可以在`torchaudio`中作为`torchaudio.transforms.MFCC`使用。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_acc,label='test')\n",
    "plt.plot(train_acc,label='train')\n",
    "plt.title(\"Accuracy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入库文件\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchaudio.transforms as T\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "\n",
    "import IPython.display as ipd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126546f0",
   "metadata": {},
   "source": [
    "# 生成数据训练list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c64ca454",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py:4563: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().replace(\n"
     ]
    }
   ],
   "source": [
    "# 定义自己的数据集\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Optional, Union\n",
    "import torchaudio\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "FOLDER_IN_ARCHIVE = \"TAL-SER\"\n",
    "EXCEPT_FOLDER = \"_background_noise_\"\n",
    "LABEL_FOLDER = 'label'\n",
    "path ='/mnt/pci-0000:00:1f.2-ata-1-part1/ZLQ/AI/data/TAL-SER/'\n",
    "label_df = pd.read_csv(path+\"label/label\",sep=\" \")\n",
    "utt2gen_df = pd.read_csv(path+\"label/utt2gen\",sep=\" \",header=None,names=['id','sex'])\n",
    "utt2spk_df = pd.read_csv(path+\"label/utt2spk\",sep=\" \",header=None,names=['id','speaker'])\n",
    "wavscp_df = pd.read_csv(path+\"label/wavscp\",sep=\" \",header=None,names=['id','path'])\n",
    "wavscp_df.sort_values('id', ignore_index=True,inplace =True)\n",
    "data_df = pd.concat([label_df, utt2spk_df['speaker'], utt2gen_df['sex'],wavscp_df['path']], axis=1)\n",
    "# data_df[\"path\"].replace(\".\\/S\", talser_path+\"S\", regex=True,inplace =True)\n",
    "del label_df\n",
    "del utt2gen_df\n",
    "del utt2spk_df\n",
    "del wavscp_df\n",
    "\n",
    "def function(P, A):\n",
    "    if  P>0:\n",
    "        if A>0:\n",
    "            return 'AH'\n",
    "        else:\n",
    "            return 'PH'\n",
    "    else:\n",
    "        if A<0:\n",
    "            return 'AL'\n",
    "        else:\n",
    "            return 'PL'\n",
    "data_df['emotion'] = data_df.apply(lambda x: function(x.P, x.A), axis = 1)\n",
    "\n",
    "\n",
    "# data_df[\"path\"].replace(\".\\/S\", FOLDER_IN_ARCHIVE+\"/S\", regex=True,inplace=True)\n",
    "# slow_tal_df = data_df[\"path\"].replace(\".\\/S\", FOLDER_IN_ARCHIVE+\"-SLOW/S\", regex=True)\n",
    "# fast_tal_df = data_df[\"path\"].replace(\".\\/S\", FOLDER_IN_ARCHIVE+\"-FAST/S\", regex=True)\n",
    "# data_df = pd.concat([tal_df, slow_tal_df, fast_tal_df], axis=0)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df,test = train_test_split(data_df, test_size=0.4, random_state=612,\n",
    "                                stratify=data_df[['emotion']])\n",
    "val_df,test_df = train_test_split(test, test_size=0.5, random_state=612,\n",
    "                                stratify=test[['emotion']])\n",
    "\n",
    "test_df[\"path\"].replace(\".\\/S\", FOLDER_IN_ARCHIVE+\"/S\", regex=True ,inplace =True)\n",
    "val_df[\"path\"].replace(\".\\/S\", FOLDER_IN_ARCHIVE+\"/S\", regex=True, inplace =True)\n",
    "tal_df = train_df[\"path\"].replace(\".\\/S\", FOLDER_IN_ARCHIVE+\"/S\", regex=True)\n",
    "slow_tal_df = train_df[\"path\"].replace(\".\\/S\", FOLDER_IN_ARCHIVE+\"-SLOW/S\", regex=True)\n",
    "fast_tal_df = train_df[\"path\"].replace(\".\\/S\", FOLDER_IN_ARCHIVE+\"-FAST/S\", regex=True)\n",
    "train_df = pd.concat([tal_df, slow_tal_df, fast_tal_df], axis=0)\n",
    "\n",
    "\n",
    "train_df.to_csv(os.path.join(path,'talser_train_list.txt'),sep=' ',index=0,header=0)\n",
    "val_df['path'].to_csv(os.path.join(path,'talser_validation_list.txt'),sep=' ',index=0,header=0)\n",
    "test_df['path'].to_csv(os.path.join(path,'talser_testing_list.txt'),sep=' ',index=0,header=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a34d2f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Rate: 16000\n",
      "Shape: (1, 160000)\n",
      "Dtype: torch.float32\n",
      " - Max:      1.000\n",
      " - Min:     -1.000\n",
      " - Mean:    -0.000\n",
      " - Std Dev:  0.158\n",
      "\n",
      "tensor([[-0.0843, -0.0746, -0.0553,  ..., -0.0817,  0.1552,  0.3113]])\n",
      "\n",
      "(1, 160000)\n",
      "AudioMetaData(sample_rate=16000, num_frames=160000, num_channels=1, bits_per_sample=16, encoding=PCM_S)\n",
      "Sample Rate: 16000\n",
      "Shape: (1, 160000)\n",
      "Dtype: torch.float32\n",
      " - Max:      1.000\n",
      " - Min:     -1.000\n",
      " - Mean:    -0.000\n",
      " - Std Dev:  0.158\n",
      "\n",
      "tensor([[-0.0843, -0.0746, -0.0553,  ..., -0.0817,  0.1552,  0.3113]])\n",
      "\n",
      "(1, 160000)\n",
      "AudioMetaData(sample_rate=16000, num_frames=160000, num_channels=1, bits_per_sample=16, encoding=PCM_S)\n",
      "Median relative difference between original and MuLaw reconstucted signals: nan%\n",
      "Sample Rate: 16000\n",
      "Shape: (1, 160000)\n",
      "Dtype: torch.float32\n",
      " - Max:      1.000\n",
      " - Min:     -1.000\n",
      " - Mean:    -0.000\n",
      " - Std Dev:  0.158\n",
      "\n",
      "tensor([[-0.0843, -0.0746, -0.0553,  ..., -0.0817,  0.1552,  0.3113]])\n",
      "\n",
      "(1, 160000)\n",
      "AudioMetaData(sample_rate=16000, num_frames=160000, num_channels=1, bits_per_sample=16, encoding=PCM_S)\n",
      "Median relative difference between original and MuLaw reconstucted signals: nan%\n"
     ]
    }
   ],
   "source": [
    "def print_stats(waveform, sample_rate=None, src=None):\n",
    "    if src:\n",
    "        print(\"-\" * 10)\n",
    "        print(\"Source:\", src)\n",
    "        print(\"-\" * 10)\n",
    "    if sample_rate:\n",
    "        print(\"Sample Rate:\", sample_rate)\n",
    "    print(\"Shape:\", tuple(waveform.shape))\n",
    "    print(\"Dtype:\", waveform.dtype)\n",
    "    print(f\" - Max:     {waveform.max().item():6.3f}\")\n",
    "    print(f\" - Min:     {waveform.min().item():6.3f}\")\n",
    "    print(f\" - Mean:    {waveform.mean().item():6.3f}\")\n",
    "    print(f\" - Std Dev: {waveform.std().item():6.3f}\")\n",
    "    print()\n",
    "    print(waveform)\n",
    "    print()\n",
    "\n",
    "# 对比两个波形的不同\n",
    "def comparewaveform(waveform1,waveform2):\n",
    "    # Compute median relative difference\n",
    "    err = ((waveform-prewaveform).abs() / prewaveform.abs()).median()\n",
    "    print(\"Median relative difference between original and MuLaw reconstucted signals: {:.2%}\".format(err))\n",
    "\n",
    "CURPATH = '/mnt/pci-0000:00:1f.2-ata-1-part1/ZLQ'\n",
    "prewaveform=None\n",
    "waveform=None\n",
    "for i in ['/AI/data/TAL-SER/SER001/99.wav','/AI/data/TAL-SER-SLOW/SER001/99.wav','/AI/data/TAL-SER-FAST/SER001/99.wav']:\n",
    "    waveform,sample_rate=torchaudio.load(CURPATH+i)\n",
    "    print_stats(waveform,sample_rate)\n",
    "    print(waveform.numpy().shape)\n",
    "    SAMPLE_WAV_PATH = CURPATH+i\n",
    "    metadata = torchaudio.info(SAMPLE_WAV_PATH)\n",
    "    print(metadata)\n",
    "    if i == '/AI/data/TAL-SER/SER001/99.wav' :\n",
    "        prewaveform = waveform\n",
    "    else:\n",
    "        comparewaveform(prewaveform,waveform)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2e313d",
   "metadata": {},
   "source": [
    "# 使用sox进行音频变速\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8e2486",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 变速\n",
    "### 0.9倍数\n",
    "# !../bashfile/waveslow.sh /mnt/pci-0000:00:1f.2-ata-1-part1/ZLQ/AI/data/TAL-SER-SLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ec5e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1.1倍数\n",
    "# !../bashfile/wavefast.sh /mnt/pci-0000:00:1f.2-ata-1-part1/ZLQ/AI/data/TAL-SER-FAST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7a34cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## 添加噪音\n",
    "\n",
    "\n",
    "\n",
    "## 提取特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967dfdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample_rate = 8000\n",
    "transform = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=new_sample_rate)\n",
    "transformed = transform(waveform)\n",
    "\n",
    "ipd.Audio(transformed.numpy(), rate=new_sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f792e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_index(word):\n",
    "    # Return the position of the word in labels\n",
    "    return torch.tensor(labels.index(word))\n",
    "\n",
    "def index_to_label(index):\n",
    "    # Return the word corresponding to the index in labels\n",
    "    # This is the inverse of label_to_index\n",
    "    return labels[index]\n",
    "\n",
    "word_start = \"积极高唤醒\"\n",
    "index = label_to_index(word_start)\n",
    "word_recovered = index_to_label(index)\n",
    "\n",
    "print(word_start, \"-->\", index, \"-->\", word_recovered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650d114f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequence(batch):\n",
    "    # Make all tensor in a batch the same length by padding with zeros\n",
    "    batch = [item.t() for item in batch]\n",
    "    batch = torch.nn.utils.rnn.pad_sequence(batch, batch_first=True, padding_value=0.)\n",
    "    return batch.permute(0, 2, 10)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # A data tuple has the form:\n",
    "    tensors, targets = [], []\n",
    "\n",
    "    # Gather in lists, and encode labels as indices\n",
    "    for waveform, _, label, *_ in batch:\n",
    "        tensors += [waveform]\n",
    "        targets += [label_to_index(label)]\n",
    "    \n",
    "    # Group the list of tensors into a batched tensor\n",
    "    tensors = pad_sequence(tensors)\n",
    "    targets = torch.stack(targets)\n",
    "    return tensors, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparation of data and helper functions.\n",
    "DEFAULT_OFFSET = 201\n",
    "SWEEP_MAX_SAMPLE_RATE = 48000\n",
    "DEFAULT_LOWPASS_FILTER_WIDTH = 6\n",
    "DEFAULT_ROLLOFF = 0.99\n",
    "DEFAULT_RESAMPLING_METHOD = \"sinc_interpolation\"\n",
    "\n",
    "def _get_log_freq(sample_rate, max_sweep_rate, offset):\n",
    "    \"\"\"Get freqs evenly spaced out in log-scale, between [0, max_sweep_rate // 2]\n",
    "\n",
    "    offset is used to avoid negative infinity `log(offset + x)`.\n",
    "\n",
    "    \"\"\"\n",
    "    start, stop = math.log(offset), math.log(offset + max_sweep_rate // 2)\n",
    "    return torch.exp(torch.linspace(start, stop, sample_rate, dtype=torch.double)) - offset\n",
    "\n",
    "\n",
    "def _get_inverse_log_freq(freq, sample_rate, offset):\n",
    "    \"\"\"Find the time where the given frequency is given by _get_log_freq\"\"\"\n",
    "    half = sample_rate // 2\n",
    "    return sample_rate * (math.log(1 + freq / offset) / math.log(1 + half / offset))\n",
    "\n",
    "\n",
    "def _get_freq_ticks(sample_rate, offset, f_max):\n",
    "    # Given the original sample rate used for generating the sweep,\n",
    "    # find the x-axis value where the log-scale major frequency values fall in\n",
    "    time, freq = [], []\n",
    "    for exp in range(2, 5):\n",
    "        for v in range(1, 10):\n",
    "            f = v * 10 ** exp\n",
    "            if f < sample_rate // 2:\n",
    "                t = _get_inverse_log_freq(f, sample_rate, offset) / sample_rate\n",
    "                time.append(t)\n",
    "                freq.append(f)\n",
    "    t_max = _get_inverse_log_freq(f_max, sample_rate, offset) / sample_rate\n",
    "    time.append(t_max)\n",
    "    freq.append(f_max)\n",
    "    return time, freq\n",
    "\n",
    "\n",
    "def get_sine_sweep(sample_rate, offset=DEFAULT_OFFSET):\n",
    "    max_sweep_rate = sample_rate\n",
    "    freq = _get_log_freq(sample_rate, max_sweep_rate, offset)\n",
    "    delta = 2 * math.pi * freq / sample_rate\n",
    "    cummulative = torch.cumsum(delta, dim=0)\n",
    "    signal = torch.sin(cummulative).unsqueeze(dim=0)\n",
    "    return signal\n",
    "\n",
    "\n",
    "def plot_sweep(\n",
    "    waveform,\n",
    "    sample_rate,\n",
    "    title,\n",
    "    max_sweep_rate=SWEEP_MAX_SAMPLE_RATE,\n",
    "    offset=DEFAULT_OFFSET,):\n",
    "    x_ticks = [100, 500, 1000, 5000, 10000, 20000, max_sweep_rate // 2]\n",
    "    y_ticks = [1000, 5000, 10000, 20000, sample_rate // 2]\n",
    "\n",
    "    time, freq = _get_freq_ticks(max_sweep_rate, offset, sample_rate // 2)\n",
    "    freq_x = [f if f in x_ticks and f <= max_sweep_rate // 2 else None for f in freq]\n",
    "    freq_y = [f for f in freq if f >= 1000 and f in y_ticks and f <= sample_rate // 2]\n",
    "\n",
    "    figure, axis = plt.subplots(1, 1)\n",
    "    axis.specgram(waveform[0].numpy(), Fs=sample_rate)\n",
    "    plt.xticks(time, freq_x)\n",
    "    plt.yticks(freq_y, freq_y)\n",
    "    axis.set_xlabel(\"Original Signal Frequency (Hz, log scale)\")\n",
    "    axis.set_ylabel(\"Waveform Frequency (Hz)\")\n",
    "    axis.xaxis.grid(True, alpha=0.67)\n",
    "    axis.yaxis.grid(True, alpha=0.67)\n",
    "    figure.suptitle(f\"{title} (sample rate: {sample_rate} Hz)\")\n",
    "    plt.show(block=True)\n",
    "\n",
    "\n",
    "def play_audio(waveform, sample_rate):\n",
    "    waveform = waveform.numpy()\n",
    "    num_channels, num_frames = waveform.shape\n",
    "    if num_channels == 1:\n",
    "        ipd.Audio(waveform[0], rate=sample_rate)\n",
    "    elif num_channels == 2:\n",
    "        ipd.Audio((waveform[0], waveform[1]), rate=sample_rate)\n",
    "    else:\n",
    "        raise ValueError(\"Waveform with more than 2 channels are not supported.\")\n",
    "\n",
    "\n",
    "def plot_specgram(waveform, sample_rate, title=\"Spectrogram\", xlim=None):\n",
    "    waveform = waveform.numpy()\n",
    "    num_channels, num_frames = waveform.shape\n",
    "    figure, axes = plt.subplots(num_channels, 1)\n",
    "    if num_channels == 1:\n",
    "        axes = [axes]\n",
    "    for c in range(num_channels):\n",
    "        axes[c].specgram(waveform[c], Fs=sample_rate)\n",
    "        if num_channels > 1:\n",
    "            axes[c].set_ylabel(f\"Channel {c+1}\")\n",
    "        if xlim:\n",
    "            axes[c].set_xlim(xlim)\n",
    "    figure.suptitle(title)\n",
    "    plt.show(block=False)\n",
    "\n",
    "\n",
    "def benchmark_resample(\n",
    "    method,\n",
    "    waveform,\n",
    "    sample_rate,\n",
    "    resample_rate,\n",
    "    lowpass_filter_width=DEFAULT_LOWPASS_FILTER_WIDTH,\n",
    "    rolloff=DEFAULT_ROLLOFF,\n",
    "    resampling_method=DEFAULT_RESAMPLING_METHOD,\n",
    "    beta=None,\n",
    "    librosa_type=None,\n",
    "    iters=5,):\n",
    "    if method == \"functional\":\n",
    "        begin = time.time()\n",
    "        for _ in range(iters):\n",
    "            F.resample(\n",
    "                waveform,\n",
    "                sample_rate,\n",
    "                resample_rate,\n",
    "                lowpass_filter_width=lowpass_filter_width,\n",
    "                rolloff=rolloff,\n",
    "                resampling_method=resampling_method,\n",
    "            )\n",
    "        elapsed = time.time() - begin\n",
    "        return elapsed / iters\n",
    "    elif method == \"transforms\":\n",
    "        resampler = T.Resample(\n",
    "            sample_rate,\n",
    "            resample_rate,\n",
    "            lowpass_filter_width=lowpass_filter_width,\n",
    "            rolloff=rolloff,\n",
    "            resampling_method=resampling_method,\n",
    "            dtype=waveform.dtype,\n",
    "        )\n",
    "        begin = time.time()\n",
    "        for _ in range(iters):\n",
    "            resampler(waveform)\n",
    "        elapsed = time.time() - begin\n",
    "        return elapsed / iters\n",
    "    elif method == \"librosa\":\n",
    "        waveform_np = waveform.squeeze().numpy()\n",
    "        begin = time.time()\n",
    "        for _ in range(iters):\n",
    "            librosa.resample(waveform_np, orig_sr=sample_rate, target_sr=resample_rate, res_type=librosa_type)\n",
    "        elapsed = time.time() - begin\n",
    "        return elapsed / iters\n",
    "\n",
    "\n",
    "def _get_sample(path, resample=None):\n",
    "    effects = [[\"remix\", \"1\"]]\n",
    "    if resample:\n",
    "        effects.extend(\n",
    "            [\n",
    "                [\"lowpass\", f\"{resample // 2}\"],\n",
    "                [\"rate\", f\"{resample}\"],\n",
    "            ]\n",
    "        )\n",
    "    return torchaudio.sox_effects.apply_effects_file(path, effects=effects)\n",
    "\n",
    "\n",
    "def plot_waveform(waveform, sample_rate, title=\"Waveform\", xlim=None, ylim=None):\n",
    "    waveform = waveform.numpy()\n",
    "\n",
    "    num_channels, num_frames = waveform.shape\n",
    "    time_axis = torch.arange(0, num_frames) / sample_rate\n",
    "\n",
    "    figure, axes = plt.subplots(num_channels, 1)\n",
    "    if num_channels == 1:\n",
    "        axes = [axes]\n",
    "    for c in range(num_channels):\n",
    "        axes[c].plot(time_axis, waveform[c], linewidth=1)\n",
    "        axes[c].grid(True)\n",
    "        if num_channels > 1:\n",
    "            axes[c].set_ylabel(f\"Channel {c+1}\")\n",
    "        if xlim:\n",
    "            axes[c].set_xlim(xlim)\n",
    "        if ylim:\n",
    "            axes[c].set_ylim(ylim)\n",
    "    figure.suptitle(title)\n",
    "    plt.show(block=False)\n",
    "\n",
    "\n",
    "def print_stats(waveform, sample_rate=None, src=None):\n",
    "    if src:\n",
    "        print(\"-\" * 10)\n",
    "        print(\"Source:\", src)\n",
    "        print(\"-\" * 10)\n",
    "    if sample_rate:\n",
    "        print(\"Sample Rate:\", sample_rate)\n",
    "    print(\"Shape:\", tuple(waveform.shape))\n",
    "    print(\"Dtype:\", waveform.dtype)\n",
    "    print(f\" - Max:     {waveform.max().item():6.3f}\")\n",
    "    print(f\" - Min:     {waveform.min().item():6.3f}\")\n",
    "    print(f\" - Mean:    {waveform.mean().item():6.3f}\")\n",
    "    print(f\" - Std Dev: {waveform.std().item():6.3f}\")\n",
    "    print()\n",
    "    print(waveform)\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962518a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_rir_path = ''\n",
    "sample_rate=16000\n",
    "rir_raw, _ = get_rir_sample(A_rir_path,resample=sample_rate)\n",
    "\n",
    "print_stats(rir_raw, sample_rate=sample_rate)\n",
    "plot_waveform(rir_raw, sample_rate)\n",
    "plot_specgram(rir_raw, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae5a2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rir = rir_raw[:, int(sample_rate * 1.01) : int(sample_rate * 1.3)]\n",
    "rir = rir / torch.norm(rir, p=2)\n",
    "rir = torch.flip(rir, [1])\n",
    "\n",
    "# print_stats(rir)\n",
    "print_stats(rir, sample_rate=sample_rate)\n",
    "plot_waveform(rir, sample_rate)\n",
    "plot_specgram(rir, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77273978",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_stats(waveform, sample_rate=sample_rate)\n",
    "plot_waveform(waveform, sample_rate)\n",
    "plot_specgram(waveform, sample_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchaudio.save('output/sample.wav', waveform, sample_rate)  # save tensor to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_audiomentations import Compose, Gain, PolarityInversion\n",
    "\n",
    "# Initialize augmentation callable\n",
    "apply_augmentation = Compose(\n",
    "    transforms=[\n",
    "        Gain(\n",
    "            min_gain_in_db=-15.0,\n",
    "            max_gain_in_db=5.0,\n",
    "            p=0.5,\n",
    "        ),\n",
    "        PolarityInversion(p=0.5)\n",
    "    ]\n",
    ")\n",
    "\n",
    "torch_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Make an example tensor with white noise.\n",
    "# This tensor represents 8 audio snippets with 2 channels (stereo) and 2 s of 16 kHz audio.\n",
    "audio_samples = torch.rand(size=(8, 2, 32000), dtype=torch.float32, device=torch_device) - 0.5\n",
    "\n",
    "# Apply augmentation. This varies the gain and polarity of (some of)\n",
    "# the audio snippets in the batch independently.\n",
    "perturbed_audio_samples = apply_augmentation(audio_samples, sample_rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchaudio.sox_effects.effect_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pdef pd.Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pdef pd.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pdoc pd.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pfile pd.DataFrame"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "494.85px",
    "left": "1678px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
